{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have builded 2 models: RNN and NB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r'train.tsv', sep='\\t')\n",
    "df_test = pd.read_csv(r'test.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Descriptive analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>20181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>12594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>12508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>9142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>5658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>4531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>as</th>\n",
       "      <td>3366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>2972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>its</th>\n",
       "      <td>2953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>2880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>this</th>\n",
       "      <td>2529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>2486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an</th>\n",
       "      <td>2448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>2333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>but</th>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>1935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>more</th>\n",
       "      <td>1642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>his</th>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>than</th>\n",
       "      <td>1566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>1495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>at</th>\n",
       "      <td>1384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>about</th>\n",
       "      <td>1358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>credits</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>until</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>niro</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ways</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemistry</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stunning</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energetic</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>substance</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powerful</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fashion</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>surprise</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slasher</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quickly</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>took</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>century</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cheap</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60s</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>efforts</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leaves</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loved</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>told</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sports</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brilliant</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>change</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vision</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           frequency\n",
       "the            20181\n",
       "and            12594\n",
       "of             12508\n",
       "to              9142\n",
       "in              5658\n",
       "is              5322\n",
       "it              4857\n",
       "that            4531\n",
       "as              3366\n",
       "with            2972\n",
       "its             2953\n",
       "for             2880\n",
       "this            2529\n",
       "film            2486\n",
       "an              2448\n",
       "movie           2333\n",
       "but             2001\n",
       "be              1935\n",
       "on              1896\n",
       "you             1832\n",
       "by              1733\n",
       "more            1642\n",
       "his             1608\n",
       "than            1566\n",
       "not             1495\n",
       "like            1428\n",
       "at              1384\n",
       "about           1358\n",
       "one             1335\n",
       "from            1320\n",
       "...              ...\n",
       "credits           70\n",
       "until             70\n",
       "niro              70\n",
       "ways              70\n",
       "post              69\n",
       "chemistry         69\n",
       "stunning          69\n",
       "alone             69\n",
       "energetic         69\n",
       "substance         69\n",
       "powerful          69\n",
       "america           69\n",
       "fashion           69\n",
       "surprise          68\n",
       "slasher           68\n",
       "group             68\n",
       "quickly           68\n",
       "took              68\n",
       "century           68\n",
       "cheap             68\n",
       "60s               68\n",
       "efforts           67\n",
       "today             67\n",
       "leaves            67\n",
       "loved             67\n",
       "told              67\n",
       "sports            67\n",
       "brilliant         67\n",
       "change            67\n",
       "vision            67\n",
       "\n",
       "[744 rows x 1 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_word = set(stopwords.words('english')) \n",
    "word_vectorizer = CountVectorizer(ngram_range=(1,1), analyzer='word', min_df=0.001)\n",
    "sparse_matrix = word_vectorizer.fit_transform(df_test['Phrase'])\n",
    "frequencies = sum(sparse_matrix).toarray()[0]\n",
    "freq = pd.DataFrame(frequencies, index=word_vectorizer.get_feature_names(), columns=['frequency'])\n",
    "freq.sort_values('frequency', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1df18841ba8>"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = df_train.Sentiment.value_counts()\n",
    "a = pd.DataFrame(a)\n",
    "a['Rating'] = a.index\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.barplot(y='Sentiment', x='Rating', data=a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Phrase'] = df_train['Phrase'].str.lower()\n",
    "df_train['Phrase'] = df_train['Phrase'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))\n",
    "df_test['Phrase'] = df_test['Phrase'].str.lower()\n",
    "df_test['Phrase'] = df_test['Phrase'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]','',x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for validation process\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#x=df_train.Phrase\n",
    "#y_target=df_train.Sentiment\n",
    "#X_train, X_val, y_train, y_val = train_test_split(x, y_target, test_size=0.2,  random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.Phrase\n",
    "y_train = df_train.Sentiment\n",
    "tokenize = Tokenizer()\n",
    "tokenize.fit_on_texts(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.Phrase\n",
    "X_train = tokenize.texts_to_sequences(X_train)\n",
    "X_test = tokenize.texts_to_sequences(X_test)\n",
    "#X_val = tokenize.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lenght = max([len(s.split()) for s in df_train['Phrase']])\n",
    "X_train = pad_sequences(X_train, max_lenght)\n",
    "X_test = pad_sequences(X_test, max_lenght)\n",
    "#X_val = sequence.pad_sequences(X_val, max_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 48)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66292, 48)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "unknown = len(tokenize.word_index)+1\n",
    "model = Sequential()\n",
    "model.add(Embedding(unknown, EMBEDDING_DIM, input_length=max_lenght))\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2 ))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, 48, 100)           1637800   \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 1,755,693\n",
      "Trainable params: 1,755,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060,)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156060, 48)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 156060 samples, validate on 31212 samples\n",
      "Epoch 1/7\n",
      "156060/156060 [==============================] - 381s 2ms/step - loss: 1.1277 - acc: 0.5486 - val_loss: 1.3774 - val_acc: 0.4982\n",
      "Epoch 2/7\n",
      "156060/156060 [==============================] - 366s 2ms/step - loss: 0.8701 - acc: 0.6425 - val_loss: 1.5668 - val_acc: 0.4662\n",
      "Epoch 3/7\n",
      "156060/156060 [==============================] - 389s 2ms/step - loss: 0.7797 - acc: 0.6770 - val_loss: 1.6759 - val_acc: 0.4564\n",
      "Epoch 4/7\n",
      "156060/156060 [==============================] - 391s 3ms/step - loss: 0.7317 - acc: 0.6952 - val_loss: 1.7451 - val_acc: 0.4511\n",
      "Epoch 5/7\n",
      "156060/156060 [==============================] - 361s 2ms/step - loss: 0.6972 - acc: 0.7075 - val_loss: 1.7654 - val_acc: 0.4448\n",
      "Epoch 6/7\n",
      "156060/156060 [==============================] - 312s 2ms/step - loss: 0.6684 - acc: 0.7196 - val_loss: 1.8649 - val_acc: 0.4406\n",
      "Epoch 7/7\n",
      "156060/156060 [==============================] - 279s 2ms/step - loss: 0.6461 - acc: 0.7276 - val_loss: 1.9208 - val_acc: 0.4391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1df3ce80c50>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=7, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    38391\n",
       "3    13844\n",
       "1    10052\n",
       "4     2274\n",
       "0     1731\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
  
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = pd.read_csv(r'sampleSubmission.csv', sep=',')\n",
    "final_pred.Sentiment=final_pred\n",
    "final_pred.to_csv(r'results.csv', sep=',', index=False)\n",
    "#Best result for testing I had 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10730\n",
      "NB: 0.612392669486095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stas\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: 0.607362552864283\n"
     ]
    }
   ],
   "source": [
    "#Additionally before I took deep learning technique, I tested Naive Bayes, \n",
    "#Random Forest and SVM approach to test which model works better.\n",
    "#RF showed best results for test data 0.62.\n",
    "#Code below\n",
    "df_train = pd.read_csv(r'train.tsv', sep='\\t')\n",
    "df_train['Phrase'] = df_train['Phrase'].str.lower()\n",
    "stop_word = set(stopwords.words('english')) \n",
    "#df_train['Phrase_no_stopwords'] = df_train['Phrase'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_word)]))\n",
    "df_train['tokezines_sents'] = df_train.apply(lambda x: nltk.word_tokenize(x['Phrase']),axis=1)\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer('english')\n",
    "df_train['tokezines_sents'] = df_train['tokezines_sents'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "df_train['tokezines_sents'] = df_train['tokezines_sents'].apply(lambda x: ' '.join(x))\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=df_train.tokezines_sents\n",
    "y=df_train.Sentiment\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2,  random_state=1)\n",
    "x_train_df = vect.fit_transform(X_train)\n",
    "x_test_df = vect.transform(X_test)\n",
    "print('Number of features:', len(vect.get_feature_names()))\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(x_train_df, y_train)\n",
    "y_pred_class = nb.predict(x_test_df)\n",
    "print('NB:', metrics.accuracy_score(y_test, y_pred_class))\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "SVM = SGDClassifier()\n",
    "SVM.fit(x_train_df, y_train)\n",
    "y_pred_class = SVM.predict(x_test_df)\n",
    "print('SVM:', metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF: 0.6242150454953224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train_df, y_train)\n",
    "y_pred_class = rfc.predict(x_test_df)\n",
    "print('RF:',metrics.accuracy_score(y_test, y_pred_class))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
